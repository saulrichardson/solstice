Logical issues identified in `src/fact_check/` (July 2025)
==========================================================

The items below describe **behavioural / design** problems found in the
fact-checking subsystem.  None of them raise exceptions at import-time, but
they can lead to duplicated work, wrong success flags, or subtle parsing
failures.


1.  claim_orchestrator.py
------------------------

1-a  Duplicate presenter execution
     • The main loop executes *evidence_presenter* unless

```python
if agent_name == "evidence_presenter" and additional_evidence_found:
    continue
```

       `additional_evidence_found` is **False** when the loop reaches the
       presenter (it is only toggled by *completeness_checker* executed just
       before).  Therefore the presenter runs inside the loop *and* a second
       time afterwards via `_run_presenter()`, causing redundant work and
       double-writing of outputs whenever **no** extra evidence was found.

1-b  Unused variable
     `initial_evidence_verified` is set but never read.

1-c  Success flag can be misleading
     `doc_result["success"] = all(a["success"] for a in doc_result["agents_run"])`
     returns **True** for an empty list (when the first agent fails and breaks
     the loop).  The document is therefore marked as successful although no
     pipeline step completed.


2.  utils/llm_parser.py
----------------------

2-a  Smart-quote replacement is a no-op
     Lines meant to normalise curly quotes perform

```python
content = content.replace('"', '"').replace('"', '"')
```

     which replaces a character with itself twice ⇒ no effect.  Same for the
     single-quote line.  Curly quotes remain unnormalised, defeating the
     goal of the helper.

2-b  Regex for string escaping is malformed
     The pattern `r'"((?:[^"\\]|\\.)*)\"'` terminates with `\"` instead
     of `"`, so it never matches and control characters inside JSON strings
     are left unescaped.  This can still yield invalid JSON after the
     “cleaning” step.


3.  study_orchestrator.py
------------------------

3-a  `loops_performed` field printed but never populated – always prints `0`.

3-b  `evidence_counts` is collected for average calculation but not used for
     anything else; no functional impact but indicates leftover code.


Impact summary
--------------

• Presenter may be executed twice per document, doubling runtime and creating
  duplicate files when no additional evidence exists.
• False “success” flags for documents where the pipeline aborted early.
• JSON cleaning may leave smart quotes / control characters unescaped,
  causing decode errors down-stream.


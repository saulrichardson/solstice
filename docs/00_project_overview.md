<!--
  This file was generated by moving the detailed portions of the original
  repository README into the new docs folder.  It serves as an in-depth
  project overview while the top-level README stays concise.
-->

<!-- NOTE: This is the content previously found in the large root README.  It
     has been moved verbatim so that the root README can remain a concise
     landing page.  Feel free to further break this file into smaller docs/*
     sections as the project evolves. -->


# Solstice

A clinical document processing pipeline with advanced layout detection and fact-checking capabilities.

## Overview

Solstice is a comprehensive system for processing clinical documents (PDFs, clinical trial data, FDA documents) that combines state-of-the-art document analysis with AI-powered fact-checking. The system is designed to handle complex medical and scientific documentation, extracting structured information and verifying claims against evidence.

### Repository Structure

```
solstice/
├── src/                    # Main source code
│   ├── cli/               # Command-line interface for all operations
│   ├── fact_check/        # Multi-agent fact-checking system
│   │   ├── agents/        # Individual evidence extraction agents
│   │   ├── orchestrators/ # Coordination of agent pipelines
│   │   └── utils/         # Fact-checking utilities
│   ├── gateway/           # API proxy service for LLM interactions
│   ├── injestion/         # Document processing pipelines
│   │   ├── scientific/    # Main pipeline for clinical/scientific PDFs
│   │   ├── marketing/     # Specialized pipeline for marketing materials
│   │   └── shared/        # Common processing utilities
│   │       ├── processing/    # Text correction and cleaning
│   │       ├── storage/       # Data persistence layer
│   │       └── visualization/ # Visual output generation
│   ├── core/              # Core utilities and logging
│   ├── interfaces/        # Shared data models and interfaces
│   └── util/              # Helper utilities
├── data/                  # Data directory (see data/README.md)
│   ├── cache/            # Processed document outputs
│   ├── claims/           # Claim definition files
│   ├── clinical_files/   # Input PDFs (clinical/scientific)
│   ├── marketing_slide/  # Input PDFs (marketing)
│   └── studies/          # Fact-checking study results
├── docker-compose.yml     # Container orchestration
├── Makefile              # Build and operation commands
└── pyproject.toml        # Package configuration
```

### Core Components

1. **Document Ingestion Pipeline** (`src/injestion/`)
   - Converts PDFs into structured, searchable JSON
   - Extracts text, tables, figures, and metadata
   - Corrects common PDF text extraction errors
   - Maintains document structure and relationships
   - Handles both scientific papers and marketing materials

2. **Fact-Checking System** (`src/fact_check/`)
   - Verifies claims against extracted document content
   - Multi-agent system where each agent has a specific role:
     - Finding relevant evidence passages
     - Validating that evidence supports claims
     - Identifying missing evidence
     - Analyzing charts and figures
   - Creates detailed evidence trails for transparency
   - Outputs structured verification reports

3. **Gateway Service** (`src/gateway/`)
   - Manages all LLM API interactions
   - Provides centralized request handling
   - Implements caching to reduce API costs
   - Handles errors and retries gracefully
   - Tracks usage and performance metrics

### Key Features

- **Accurate PDF Processing**: Extracts text, tables, and figures from complex medical documents
- **Intelligent Text Correction**: Automatically fixes PDF extraction errors while preserving medical terminology
- **Evidence-Based Verification**: Fact-checks claims by finding and validating supporting evidence in documents
- **Transparent Results**: Every claim verification includes exact quotes and page references
- **Production Ready**: Scalable deployment with monitoring and error handling

### Use Cases

- Processing clinical trial protocols and results
- Extracting data from FDA submissions and approvals
- Verifying claims in medical literature
- Building structured datasets from unstructured clinical documents
- Analyzing marketing materials for regulatory compliance

### How It Works

1. **Place PDFs** in `data/clinical_files/` or `data/marketing_slide/`
2. **Run ingestion** to extract structured content: `python -m src.cli ingest`
3. **Run fact-checking** to verify claims: `python -m src.cli run-study`
4. **View results** in `data/cache/` (extracted content) and `data/studies/` (fact-check results)

The system processes documents through a pipeline:
- PDF → Layout Detection → Text Extraction → Structured JSON
- Claims + Documents → Evidence Extraction → Verification → Study Results

## Architecture Details

### Document Processing Flow

```
Input PDFs → Ingestion Pipeline → Structured JSON → Fact-Checking → Evidence Results
                     ↓                                      ↓
              Layout Detection                       Multi-Agent System
              Text Correction                        Evidence Extraction
              Table/Figure Extraction                Verification
                                                    Image Analysis
```

### Module Responsibilities

**CLI Module** (`src/cli/`): Command-line interface
- `ingest`: Convert PDFs to structured JSON
- `run-study`: Run fact-checking on claims
- `gateway`: Start/stop API service

**Ingestion Module** (`src/injestion/`): Document processing
- **Scientific Pipeline**: For clinical trials, FDA documents, research papers
  - Handles dense text, complex tables, scientific figures
  - Preserves citations and cross-references
- **Marketing Pipeline**: For presentations and marketing materials  
  - Better handling of visual layouts and branding
  - Extracts marketing claims and visual evidence
- **Text Processing**: Corrects extraction errors, preserves medical terms

**Fact-Check Module** (`src/fact_check/`): Claim verification
- **Evidence Pipeline**:
  1. Extract relevant passages from documents
  2. Verify passages actually support claims
  3. Check for missing evidence
  4. Analyze supporting images/charts
  5. Generate final evidence report
- **Orchestration**: Manages parallel processing of multiple claims

**Gateway Module** (`src/gateway/`): API management
- Proxies requests to OpenAI/other LLMs
- Implements rate limiting and retries
- Caches responses to reduce costs
- Provides usage analytics

### Data Flow

1. **Input**: PDFs placed in `data/clinical_files/` or `data/marketing_slide/`
2. **Processing**: Ingestion extracts content to `data/cache/{document_name}/`
3. **Fact-Checking**: Agents process claims and save to `data/cache/{document_name}/agents/`
4. **Results**: Final study results saved to `data/studies/`

### Text Extraction and Correction

The system employs a multi-stage approach to extract and correct text from PDFs:

1. **Raw Text Extraction**
   - Uses PyMuPDF (fitz) to extract text while preserving document structure
   - Maintains paragraph boundaries and text flow
   - Extracts tables as structured data when possible

2. **Intelligent Text Correction**
   - **Spacing Correction**: Fixes concatenated words common in PDFs
     - "theinformationneeded" → "the information needed"
     - Uses WordNinja with Google n-gram frequencies
   - **Medical Term Preservation**: Maintains specialized terminology
     - Preserves drug names, medical procedures, dosages
     - Protects registered trademarks (e.g., "Flublok®")
   - **Context-Aware Processing**: Different rules for different content
     - Scientific text: preserves chemical formulas, units
     - Marketing text: maintains brand styling

3. **LLM-Assisted Enhancement** (Fact-Checking Phase)
   - LLMs analyze extracted text for evidence relevance
   - **Guardrails prevent hallucination**:
     - LLMs can only reference text explicitly present in documents
     - All evidence must include exact quotes with page numbers
     - Verification agents double-check all extracted evidence
   - **No content generation**: LLMs extract and verify, never create

This multi-layered approach ensures high-quality text extraction while preventing AI-generated content from contaminating the evidence base.

## Getting Started

For detailed installation instructions, please see the [Installation Guide](01_installation.md).

### Quick Start

```bash
# Clone and setup
git clone <repository-url> && cd solstice
make install              # Install dependencies (Python 3.11/3.12 required)

# Process documents
cp your-documents.pdf data/clinical_files/
make ingest              # Extract structured content

# Run fact-checking
make run-study           # Verify claims against evidence
```

## Development

### Code Quality

```bash
# Format code automatically
make format

# Check code style
make lint

# Run tests
pytest
```

### Project Structure

```
solstice/
├── data/
│   ├── clinical_files/   # Input PDFs go here
│   └── cache/           # Processed outputs stored here
├── src/
│   ├── cli/             # Command-line interface
│   ├── fact_check/      # Fact-checking agents
│   ├── gateway/         # API proxy service  
│   ├── injestion/       # PDF processing pipelines
│   │   ├── scientific/  # Main pipeline for scientific/clinical PDFs
│   │   ├── marketing/   # Specialized pipeline for Flublok marketing PDFs
│   │   └── shared/      # Common utilities
│   │       ├── processing/  # Text cleaning & correction
│   │       ├── storage/     # Data persistence
│   │       └── visualization/ # Visual output generation
│   ├── core/            # Core utilities
│   ├── interfaces/      # Shared interfaces
│   └── util/            # Helper utilities
├── docker-compose.yml   # Container orchestration
├── Makefile            # Common commands
├── pyproject.toml      # Package & dependencies
├── requirements-*.txt  # Dependency constraints
└── .python-version     # Python 3.11.9 (for pyenv)
```

### Adding New Features

1. **New Document Types**: Add parsers in `src/injestion/`
2. **New Fact-Check Agents**: Add to `src/fact_check/agents/`
3. **New API Endpoints**: Modify `src/gateway/`

### Common Commands

```bash
make help         # Show all available commands
make install      # Install base package
make verify       # Check installation
make up          # Start services
make logs        # View logs
make down        # Stop services
make format      # Format code
make lint        # Check code style
make clean       # Remove cache files
```
